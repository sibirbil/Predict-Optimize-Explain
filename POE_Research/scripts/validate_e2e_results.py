#!/usr/bin/env python
"""
Quick E2E validation of existing PTO results.

Validates that the complete pipeline produced correct results.
"""
import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent / 'src'))

import pandas as pd
import numpy as np
import json

def main():
    print("=" * 70)
    print("E2E VALIDATION - CHECKING EXISTING RESULTS")
    print("=" * 70)

    # Check for corrected results
    # Try both paths (running from project root or from POE_Research)
    if Path('POE_Research/outputs/pto/results').exists():
        results_dir = Path('POE_Research/outputs/pto/results')
    elif Path('outputs/pto/results').exists():
        results_dir = Path('outputs/pto/results')
    else:
        results_dir = Path('../outputs/pto/results')

    corrected_json = results_dir / 'monthly_results_CORRECTED.json'
    corrected_csv = results_dir / 'summary_stats_CORRECTED.csv'

    if not corrected_json.exists() or not corrected_csv.exists():
        print("\n‚ùå Corrected results not found!")
        print("Run: python scripts/fix_pto_results.py")
        return False

    print("\n‚úì Found corrected results files")

    # Load data
    with open(corrected_json, 'r') as f:
        results = json.load(f)

    stats_df = pd.read_csv(corrected_csv)

    print(f"\n‚úì Loaded results:")
    print(f"  Strategies: {len(stats_df)}")
    print(f"  Months: {stats_df['n_months'].iloc[0]}")

    # Validation checks
    print("\n" + "=" * 70)
    print("VALIDATION CHECKS")
    print("=" * 70)

    checks = []

    # Check 1: Correct number of months
    n_months = stats_df['n_months'].iloc[0]
    months_ok = 100 <= n_months <= 120  # Should be ~107-108
    checks.append(("Test period length (100-120 months)", months_ok, f"{n_months} months"))

    # Check 2: All Sharpes positive
    all_positive = (stats_df['sharpe_a'] > 0).all()
    min_sharpe = stats_df['sharpe_a'].min()
    checks.append(("All Sharpe ratios > 0", all_positive, f"min={min_sharpe:.2f}"))

    # Check 3: MVO outperforms EW
    ew_sharpe = stats_df[stats_df['strategy'] == 'equal_weight']['sharpe_a'].values[0]
    mvo_sharpe = stats_df[stats_df['strategy'].str.contains('kappa_0.0')]['sharpe_a'].values[0]
    mvo_better = mvo_sharpe > ew_sharpe * 0.9  # At least 90% of EW
    checks.append(("MVO competitive with Equal Weight", mvo_better, f"MVO={mvo_sharpe:.2f} vs EW={ew_sharpe:.2f}"))

    # Check 4: Reasonable Sharpe range
    sharpe_range_ok = (stats_df['sharpe_a'] > 0.3).all() and (stats_df['sharpe_a'] < 2.0).all()
    sharpe_range = f"{stats_df['sharpe_a'].min():.2f} to {stats_df['sharpe_a'].max():.2f}"
    checks.append(("Sharpe ratios in range (0.3-2.0)", sharpe_range_ok, sharpe_range))

    # Check 5: Kappa effect
    kappa_strategies = stats_df[stats_df['strategy'].str.contains('diagSigma')].sort_values('strategy')
    if len(kappa_strategies) >= 2:
        kappa_sharpes = kappa_strategies['sharpe_a'].values
        # Higher kappa should generally have lower volatility
        kappa_vols = kappa_strategies['vol_a'].values
        vol_decreases = kappa_vols[-1] <= kappa_vols[0]  # Last (high kappa) <= First (low kappa)
        checks.append(("Kappa effect (higher Œ∫ ‚Üí lower vol)", vol_decreases, f"Œ∫=0: {kappa_vols[0]:.2%}, Œ∫=max: {kappa_vols[-1]:.2%}"))

    # Check 6: Reasonable max drawdown
    dd_reasonable = (stats_df['max_drawdown'] > -0.5).all()
    max_dd = stats_df['max_drawdown'].min()
    checks.append(("Max drawdowns > -50%", dd_reasonable, f"worst={max_dd:.2%}"))

    # Check 7: Hit rates positive
    hit_reasonable = (stats_df['hit_rate'] > 50).all()
    avg_hit = stats_df['hit_rate'].mean()
    checks.append(("Hit rates > 50%", hit_reasonable, f"avg={avg_hit:.1f}%"))

    # Check 8: Cumulative returns positive
    cum_positive = (stats_df['cum_simple'] > 0).all()
    avg_cum = stats_df['cum_simple'].mean()
    checks.append(("All cumulative returns > 0", cum_positive, f"avg={avg_cum:.2%}"))

    # Print results
    all_passed = True
    for check_name, passed, details in checks:
        status = "‚úÖ" if passed else "‚ùå"
        print(f"{status} {check_name:.<50} {details}")
        if not passed:
            all_passed = False

    # Print summary
    print("\n" + "=" * 70)
    print("PERFORMANCE SUMMARY")
    print("=" * 70)

    print("\n{:<20} {:>12} {:>12} {:>10} {:>12}".format(
        "Strategy", "Annual Ret", "Annual Vol", "Sharpe", "Max DD"
    ))
    print("-" * 70)

    for _, row in stats_df.iterrows():
        print("{:<20} {:>11.2%} {:>11.2%} {:>10.2f} {:>11.2%}".format(
            row['strategy'],
            row['mean_a'],
            row['vol_a'],
            row['sharpe_a'],
            row['max_drawdown']
        ))

    # Final verdict
    print("\n" + "=" * 70)
    if all_passed:
        print("‚úÖ ALL E2E VALIDATION CHECKS PASSED!")
        print("=" * 70)
        print("\nüéâ The PTO implementation is VALIDATED and production-ready!")
        print("\nKey Results:")
        print(f"  ‚Ä¢ Test period: {n_months} months")
        print(f"  ‚Ä¢ Best strategy: {stats_df.loc[stats_df['sharpe_a'].idxmax(), 'strategy']}")
        print(f"  ‚Ä¢ Best Sharpe: {stats_df['sharpe_a'].max():.2f}")
        print(f"  ‚Ä¢ MVO vs EW: {mvo_sharpe:.2f} vs {ew_sharpe:.2f}")
        return True
    else:
        print("‚ö†Ô∏è  SOME E2E VALIDATION CHECKS FAILED")
        print("=" * 70)
        print("\nPlease review the failed checks above.")
        return False

if __name__ == '__main__':
    success = main()
    exit(0 if success else 1)
